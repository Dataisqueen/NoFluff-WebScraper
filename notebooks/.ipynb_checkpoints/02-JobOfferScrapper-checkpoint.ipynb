{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22f43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importujemy biblioteki\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b32d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upewniamy się, że scraper nie pójdzie do kolejnej strony, jeśli bieżąca jest pusta\n",
    "\n",
    "def is_page_empty(bs) -> bool:\n",
    "    empty_condition = bs.find('h2', class_='text-white font-weight-bold')\n",
    "\n",
    "    if empty_condition is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapujemy widełki wynagrodzenia stanowiska\n",
    "\n",
    "def parse_salary(salary) -> dict:\n",
    "    bounds = re.findall('[0-9]+', salary.replace(' ', ''))\n",
    "    low_bound = bounds[0]\n",
    "    high_bound = bounds[1] if len(bounds) > 1 else bounds[0]\n",
    "    currency = salary.split()[-1]\n",
    "\n",
    "    return {'low': low_bound,\n",
    "            'high': high_bound,\n",
    "            'currency': currency}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapujemy miasta\n",
    "\n",
    "def parse_city(city) -> dict:\n",
    "    if re.search('(Zdalna)', city):\n",
    "         _city = \"Zdalna\"\n",
    "         country = 'N/A'\n",
    "    else:       \n",
    "        (_city, country) = city.split(',')\n",
    "        country = country.strip()\n",
    "\n",
    "    return {'city': _city, 'country': country}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jobs(jobs) -> list:\n",
    "    results = []\n",
    "    \n",
    "    for job in jobs:\n",
    "        results.append(parse_job(job))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926de0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zbieramy wszystkie dane - misasto, widełki, nazwa stanowiska, firmę, stack technologiczny\n",
    "\n",
    "def parse_job(job) -> dict:\n",
    "    job_info = job.find('div', class_='posting-info position-relative d-none d-lg-flex flex-grow-1').find_all('span')\n",
    "    \n",
    "    salary = job_info[0].text.strip()\n",
    "    salary_data = parse_salary(salary)\n",
    "    \n",
    "    location = job.find('nfj-posting-item-city')\n",
    "    if location is None:\n",
    "        location = job_info[1]\n",
    "\n",
    "    location = location.text.strip()\n",
    "    location = parse_city(location)\n",
    "\n",
    "    name = job.find('h2', class_='posting-title__position').text.strip()\n",
    "    \n",
    "    company = job.find('span', class_='posting-title__company').text.replace('w', '').strip()\n",
    "\n",
    "    technology = job.find('a', class_='btn btn-outline-secondary btn-sm text-truncate')\n",
    "    if technology:\n",
    "        technology = technology.text.strip()\n",
    "    else:\n",
    "        technology = 'N/A'\n",
    "\n",
    "    return {\n",
    "        'location_city': location,\n",
    "        'salary': salary_data,\n",
    "        'name': name,\n",
    "        'company': company,\n",
    "        'technology': technology\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(page) -> list:\n",
    "    results = []\n",
    "\n",
    "    jobs = [x.parent for x in page.find_all('div', class_='posting-image')]\n",
    "    page_data = parse_jobs(jobs)\n",
    "    results += page_data\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odpalamy wszystkie zapisane wcześniej html i iterujemy w celu zapisania w formie .csv\n",
    "\n",
    "data_dir = '../data/raw'\n",
    "results = []\n",
    "\n",
    "for entry in os.scandir(data_dir):\n",
    "    with open(\n",
    "        os.path.join(data_dir, entry.name),\n",
    "        encoding='UTF-8') as f:\n",
    "            html = f.read()\n",
    "\n",
    "    job = entry.name.split('_')[0]\n",
    "    bs = BeautifulSoup(html)\n",
    "    \n",
    "    offers = get_data(bs)\n",
    "    for offer in offers:\n",
    "        offer['job'] = job\n",
    "    results += offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7004422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(results, sep='_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d454a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zapisujemy w .csv\n",
    "df.to_csv('../data/interim/job_offers.csv', sep=';', encoding='UTF', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
